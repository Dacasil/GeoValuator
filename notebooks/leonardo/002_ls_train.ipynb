{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2c7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GeoValuator import DATA_DIR\n",
    "import os\n",
    "import yaml\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2c335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District to bin mapping:\n",
      "{'Britz': 0, 'Falkenhagener Feld': 0, 'Fennpfuhl': 0, 'Gropiusstadt': 0, 'Marienfelde': 0, 'Marzahn': 0, 'Neu-Hohenschönhausen': 0, 'Staaken': 0, 'Baumschulenweg': 1, 'Biesdorf': 1, 'Buckow': 1, 'Friedrichshagen': 1, 'Lichtenrade': 1, 'Mariendorf': 1, 'Wittenau': 1, 'Buch': 2, 'Charlottenburg-Nord': 2, 'Friedenau': 3, 'Hellersdorf': 2, 'Karow': 2, 'Lankwitz': 2, 'Lichtenberg': 2, 'Tempelhof': 2, 'Wilhelmstadt': 2, 'Johannisthal': 3, 'Nikolassee': 3, 'Rahnsdorf': 3, 'Rudow': 3, 'Spandau': 3, 'Tegel': 3, 'Alt-Hohenschönhausen': 4, 'Friedrichsfelde': 4, 'Grünau': 4, 'Hakenfelde': 5, 'Heiligensee': 4, 'Niederschönhausen': 4, 'Reinickendorf': 4, 'Siemensstadt': 4, 'Französisch Buchholz': 5, 'Frohnau': 5, 'Kaulsdorf': 5, 'Mahlsdorf': 5, 'Schmöckwitz': 5, 'Wedding': 5, 'Zehlendorf': 5, 'Alt-Treptow': 6, 'Altglienicke': 6, 'Gesundbrunnen': 6, 'Karlshorst': 6, 'Kreuzberg': 6, 'Lichterfelde': 6, 'Oberschöneweide': 6, 'Heinersdorf': 7, 'Köpenick': 7, 'Neukölln': 7, 'Pankow': 7, 'Steglitz': 7, 'Wannsee': 7, 'Weißensee': 7, 'Westend': 7, 'Adlershof': 8, 'Charlottenburg': 8, 'Moabit': 8, 'Niederschöneweide': 8, 'Prenzlauer Berg': 8, 'Rummelsburg': 8, 'Schöneberg': 8, 'Dahlem': 9, 'Friedrichshain': 9, 'Grunewald': 9, 'Halensee': 9, 'Mitte': 9, 'Schmargendorf': 9, 'Tiergarten': 9, 'Wilmersdorf': 9}\n"
     ]
    }
   ],
   "source": [
    "with open('download_checkpoint.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a district to bin mapping\n",
    "district_bin_mapping = {}\n",
    "\n",
    "for item in data['successful_downloads']:\n",
    "    district = item['district']\n",
    "    bin_id = item['price_bin']\n",
    "    district_bin_mapping[district] = bin_id\n",
    "\n",
    "# Use mapping to label your images\n",
    "IMAGE_BASE_DIR = os.path.join(DATA_DIR, \"processed\", \"images\")\n",
    "\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "district_names_list = []\n",
    "\n",
    "# Get all district folders\n",
    "all_district_folders = [d for d in os.listdir(IMAGE_BASE_DIR) \n",
    "                       if os.path.isdir(os.path.join(IMAGE_BASE_DIR, d))]\n",
    "\n",
    "# Load images and assign bin labels using the mapping\n",
    "for district_folder in all_district_folders:\n",
    "    if district_folder in district_bin_mapping:\n",
    "        bin_id = district_bin_mapping[district_folder]\n",
    "        district_image_dir = os.path.join(IMAGE_BASE_DIR, district_folder)\n",
    "        \n",
    "        # Get all images in this district folder\n",
    "        pattern = os.path.join(district_image_dir, '*.jpg')\n",
    "        image_files = glob.glob(pattern)\n",
    "        \n",
    "        for image_path in image_files:\n",
    "            image_paths.append(image_path)\n",
    "            image_labels.append(bin_id)\n",
    "            district_names_list.append(district_folder)\n",
    "\n",
    "# Create DataFrame\n",
    "image_df = pd.DataFrame({\n",
    "    'image_path': image_paths,\n",
    "    'label': image_labels,\n",
    "    'district': district_names_list\n",
    "})\n",
    "\n",
    "NUM_LABELS = 10\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in range(NUM_LABELS):\n",
    "\n",
    "    label_images = image_df[image_df['label'] == i]\n",
    "    label_paths = label_images['image_path'].tolist()\n",
    "\n",
    "# Group images by label\n",
    "label_groups = {}\n",
    "for label in image_df['label'].unique():\n",
    "    label_groups[label] = image_df[image_df['label'] == label]\n",
    "\n",
    "# Split each label separately\n",
    "train_dfs, val_dfs, test_dfs = [], [], []\n",
    "\n",
    "for label, group in label_groups.items():\n",
    "    train_val, test = train_test_split(group, test_size=0.0654, random_state=42)\n",
    "    train, val = train_test_split(train_val, test_size=0.07, random_state=42)\n",
    "    \n",
    "    train_dfs.append(train)\n",
    "    val_dfs.append(val)\n",
    "    test_dfs.append(test)\n",
    "\n",
    "# Combine all labels\n",
    "train_df = pd.concat(train_dfs).reset_index(drop=True)\n",
    "val_df = pd.concat(val_dfs).reset_index(drop=True)\n",
    "test_df = pd.concat(test_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958afbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n",
      "Train batches: 547\n",
      "Val batches: 42\n",
      "Test batches: 42\n"
     ]
    }
   ],
   "source": [
    "class StreetViewDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['image_path']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Define transforms for B3 (300x300)\n",
    "INPUT_SIZE = 300\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Use ImageNet means and std\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = StreetViewDataset(train_df, transform=train_transform)\n",
    "val_dataset = StreetViewDataset(val_df, transform=val_transform)\n",
    "test_dataset = StreetViewDataset(test_df, transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Classification Model (für deine 10 Bins)\n",
    "class EfficientNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10, model_name='efficientnet_b3'):\n",
    "        super(EfficientNetClassifier, self).__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(model_name, \n",
    "                                         pretrained=True,\n",
    "                                         num_classes=0,\n",
    "                                         global_pool='avg')\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.backbone.num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "# Put model on GPU\n",
    "model = EfficientNetClassifier(num_classes=10, model_name='efficientnet_b3')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"Model is on: {next(model.parameters()).device}\")\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, scheduler=None):\n",
    "    model = model.to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    best_val_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for images, labels in train_pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.long().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Update progress bar with current metrics\n",
    "            current_acc = 100 * correct_train / total_train\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': loss.item(),\n",
    "                'Acc': f'{current_acc:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch training metrics\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = 100 * correct_train / total_train\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.long().to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                \n",
    "                # Calculate validation accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate epoch validation metrics\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = 100 * correct_val / total_val\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "        \n",
    "        # Step scheduler\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Print detailed epoch summary\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.2f}%')\n",
    "        print(f'  Val Loss:   {epoch_val_loss:.4f} | Val Acc:   {epoch_val_acc:.2f}%')\n",
    "        \n",
    "        # Save best model based on validation accuracy\n",
    "        if epoch_val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = epoch_val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'  ↳ New best model saved! (Val Acc: {epoch_val_acc:.2f}%)')\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    ax1.plot(train_losses, label='Train Loss')\n",
    "    ax1.plot(val_losses, label='Val Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot accuracies\n",
    "    ax2.plot(train_accuracies, label='Train Accuracy')\n",
    "    ax2.plot(val_accuracies, label='Val Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use CrossEntropy Loss für Classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Stage 1: Feature Extraction\n",
    "print(\"=== Stage 1: Feature Extraction ===\")\n",
    "\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer_stage1 = optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train with metrics\n",
    "train_losses_s1, val_losses_s1, train_acc_s1, val_acc_s1 = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer_stage1, \n",
    "    num_epochs=10\n",
    ")\n",
    "\n",
    "# Stage 2: Fine-Tuning\n",
    "print(\"\\n=== Stage 2: Fine-Tuning ===\")\n",
    "\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer_stage2 = optim.Adam(\n",
    "    [{'params': model.classifier.parameters(), 'lr': 1e-4},\n",
    "     {'params': model.backbone.parameters(), 'lr': 1e-5}]\n",
    ")\n",
    "\n",
    "scheduler = StepLR(optimizer_stage2, step_size=5, gamma=0.1)\n",
    "\n",
    "train_losses_s2, val_losses_s2, train_acc_s2, val_acc_s2 = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer_stage2, \n",
    "    num_epochs=20, scheduler=scheduler\n",
    ")\n",
    "\n",
    "# Plot metrics\n",
    "print(\"\\n=== Stage 1 Metrics ===\")\n",
    "plot_metrics(train_losses_s1, val_losses_s1, train_acc_s1, val_acc_s1)\n",
    "\n",
    "print(\"\\n=== Stage 2 Metrics ===\")\n",
    "plot_metrics(train_losses_s2, val_losses_s2, train_acc_s2, val_acc_s2)\n",
    "\n",
    "# Combine all metrics for full training view\n",
    "full_train_losses = train_losses_s1 + train_losses_s2\n",
    "full_val_losses = val_losses_s1 + val_losses_s2\n",
    "full_train_accs = train_acc_s1 + train_acc_s2\n",
    "full_val_accs = val_acc_s1 + val_acc_s2\n",
    "\n",
    "print(\"\\n=== Full Training Metrics ===\")\n",
    "plot_metrics(full_train_losses, full_val_losses, full_train_accs, full_val_accs)\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.long().to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# Final Evaluation\n",
    "print(\"\\n=== Final Evaluation ===\")\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "accuracy = evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoValuator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
